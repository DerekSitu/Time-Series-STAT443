+sqrt((p_online_hat * (1 - p_online_hat)) / n++(p_inperson_hat * (1 - p_inperson_hat)) /
n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
online = 556
inperson = 587
n = online + inperson
p_online_hat = online / n
p_inperson_hat = inperson / n
tStat = (p_online_hat - p_inperson_hat) /
sqrt((p_online_hat * (1 - p_online_hat))/n +
(p_inperson_hat * (1 - p_inperson_hat))/n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
n = 556 + 587
p_online_hat = 556 / n
p_inperson_hat = 578 / n
tStat = (p_online_hat - p_inperson_hat) /
+sqrt((p_online_hat * (1 - p_online_hat)) / n++(p_inperson_hat * (1 - p_inperson_hat)) /
n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
online = 556
inperson = 587
n = online + inperson
p_online_hat = online / n
p_inperson_hat = inperson / n
tStat = (p_online_hat - p_inperson_hat) /
sqrt((p_online_hat * (1 - p_online_hat))/n +
(p_inperson_hat * (1 - p_inperson_hat))/n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
n = 556 + 587
p_online_hat = 556 / n
p_inperson_hat = 587 / n
tStat = (p_online_hat - p_inperson_hat) /
+sqrt((p_online_hat * (1 - p_online_hat)) / n++(p_inperson_hat * (1 - p_inperson_hat)) /
n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
online = 556
inperson = 587
n = online + inperson
p_online_hat = online / n
p_inperson_hat = inperson / n
tStat = (p_online_hat - p_inperson_hat) /
sqrt((p_online_hat * (1 - p_online_hat))/n +
(p_inperson_hat * (1 - p_inperson_hat))/n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
n = 556 + 587
p_online_hat = 556 / n
p_inperson_hat = 578 / n
tStat = (p_online_hat - p_inperson_hat) /
+sqrt((p_online_hat * (1 - p_online_hat)) / n++(p_inperson_hat * (1 - p_inperson_hat)) /
n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
online = 556
inperson = 587
n = online + inperson
p_online_hat = online / n
p_inperson_hat = inperson / n
tStat = (p_online_hat - p_inperson_hat) /
sqrt((p_online_hat * (1 - p_online_hat))/n +
(p_inperson_hat * (1 - p_inperson_hat))/n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
online = 570
inperson = 613
n = online + inperson
p_online_hat = online / n
p_inperson_hat = inperson / n
tStat = (p_online_hat - p_inperson_hat) /
sqrt((p_online_hat * (1 - p_online_hat))/n +
(p_inperson_hat * (1 - p_inperson_hat))/n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
pValue2 = pnorm(tStat, mean = 0, sd = 1)
pValue2
online = 570
inperson = 613
n = online + inperson
p_online_hat = online / n
p_inperson_hat = inperson / n
tStat = (p_online_hat - p_inperson_hat) /
sqrt((p_online_hat * (1 - p_online_hat))/n +
(p_inperson_hat * (1 - p_inperson_hat))/n)
pValue = 2 * pnorm(tStat, mean = 0, sd = 1)
pValue
## P(p_online_hat = p_inperson_hat | p_online = p_inperson)
1 - pValue
## P(p_online_hat != p_inperson_hat | p_online = p_inperson)
?stopifnot
library(knitr)
library(tseries)
setwd("C:/Users/dsder/OneDrive/Desktop/STAT_443/Lab_1")
?read.csv
setwd("C:/Users/dsder/OneDrive/Desktop/STAT_443/Lab_1")
library(tseries)
dat <- read.csv("LakeLevels.csv", header = TRUE)
dat <- read.csv("LakeLevels.csv", col_names = TRUE)
help(tidyverse::read.csv)
?tidyverse::read.csv
?read.csv
??read.csv
??tidyverse::read.csv
??tidyverse
?read.csv
?read_csv
setwd("C:/Users/dsder/OneDrive/Desktop/STAT_443/Lab_1")
library(tseries)
dat <- read.csv("LakeLevels.csv", header = TRUE)
head(dat, 10)
tail(dat, 10)
?plot
plot(dat)
plot.data.frame(dat)
plot.dataframe(dat)
?plot
names(dat)
dat$name
plot.default(x = "Date", y = "LakeLevel")
plot.default(x = "Date", y = "LakeLevel", xlim = 100, ylim = 4000)
View(dat)
?plot
setwd("C:/Users/dsder/OneDrive/Desktop/STAT_443/Lab_1")
plot(x = "Date", y = "LakeLevel")
plot(x = Date, y = LakeLevel)
Date
"Date"
View(dat)
plot(x = "Date", y = "LakeLevel", xlim = 20)
View(dat)
plot(x = "Date", y = "LakeLevel", xlim = "1/6/2007")
View(dat)
plot(x = "Date", y = "LakeLevel", xlim = 1/6/2007)
## 1b Creating a time series object
is.ts(dat)
?ts
View(dat)
length(dat)
obs(dat)
?nobs
nobs(dat)
?observations
?nobs
?obs
?nrow
nrow(dat)
?ts
ts(data = dat, start = 1, end = nrow(dat), frequency = 1)
ts(data = dat, start = 1, end = nrow(dat))
?ts
x = ts(data = dat, start = 1, end = nrow(dat)) #
x = ts(data = dat, start = 1, frequency = 12) #
x
View(dat)
x = ts(data = dat, start = 1, frequency = 365) #
View(x)
View(x)
x = ts(data = dat, start = 1, frequency = 1) #
x = ts(data = dat, start = c(2007, 1), frequency = 4) #
x = ts(data = dat, start = c(2007, 1), frequency = 365) #
x = ts(data = dat, start = c(2007, 1), frequency = 365) #
x = ts(data = dat, start = c(2007, 1), frequency = 365.25) #
x = ts(data = dat, start = c(2007, 1), frequency = 365) #
?plot
x = ts(data = dat, start = 1, end = 1826) #
?plot
## 1c Plotting time series ##
plot(x, main="Daily lake depth levels", xlab="Year", ylab="meters")
x
names(ts)
names(x)
names(dat)
?ts
dat$Date
dat$LakeLevel
?plot
plot(x = dat$Date, y = dat$LakeLevel)
plot(x = dat$Date, y = dat$LakeLevel, xlim=50, ylim=4000)
plot(x = dat$Date, y = dat$LakeLevel, xlim=c(0,50), ylim=c(0,5000))
x$Date
x$LakeLevel
plot(x = dat$Date, y = dat$LakeLevel, xlim=c(1,1826), ylim=c(0,5000))
?plot
## 1c Plotting time series ##
plot(x, main="Daily lake depth levels", xlab="Year", ylab="meters")
?ts
x = ts(data = dat$LakeLevel, start = 1, end = nrow(dat)) #
x = ts(data = dat$LakeLevel, start = c(2007, 1), end = c(2011, 365)) #
x = ts(data = dat$LakeLevel, start = c(2007, 1), frequency = 365) #
x = ts(data = dat$LakeLevel, start = 1, frequency = nrow(dat)) #
## 1c Plotting time series ##
plot(x, main="Daily lake depth levels", xlab="Year", ylab="meters")
x = ts(data = dat$LakeLevel, start = c(2007, 1), end = c(2011, 365),
deltat=1/365)
x = ts(data = dat$LakeLevel, start = 1, end = nrow(dat))
tinytex::install_tinytex()
?plot
plot(dat$LakeLevel, ylab="Lake level", main="Daily lake levels")
?ts
is.ts(dat$LakeLevel)
is.ts(dat)
x = ts(data = dat$LakeLevel, start=c(2007, 1), frequency=365)
View(dat)
x
x <- ts(data = dat$LakeLevel, start=c(2007, 1), frequency=365)
plot(x, ylab="Lake level", main="Daily lake levels")
?rnorm
# 200 independent observations
rnorm(200)
rnorm(200)
y <- ts(rnorm(200))
y
abs(y) > 2
sum(abs(y) > 2)
set.seed(2022)
rnorm(200)
y <- ts(rnorm(200))
sum(abs(y) > 2)
# create the sample autocorrelation function
acf(y, lag.max=30)
acf(y, lag.max=30, plot = F)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
b <- ts(rnorm(200))
sum(abs(b) > 2)
v<-rnorm(200)
vector = c()
acc=50
while (acc > 0) {
i <- rnorm(200)
vector = c(vector, sum(abs(i) > 2))
}
vector
vector = c()
acc=50
while (acc > 0) {
i <- rnorm(200)
vector = c(vector, sum(abs(i) > 2))
acc = acc - 1
}
vector
vector
vector = c()
acc=50
while (acc > 0) {
i <- rnorm(200)
vector = c(vector, sum(abs(i) > 2))
acc = acc - 1
}
vector
vector = c()
acc=50
while (acc > 0) {
i <- rnorm(200)
vector = c(vector, sum(abs(i) > 2))
acc = acc - 1
}
vector
acc=50
while (acc > 0) {
i <- rnorm(200)
vector = c(vector, sum(abs(i) > 2))
acc = acc - 1
}
i <- rnorm(200)
vector = c(vector, sum(abs(i) > 2))
acc = acc - 1
vector
average(vector)
avg(vector)
?average
?avg
mean(vector)
vector
# plot
plot(x, xlab="Year", ylab="Lake level", main="Daily lake levels")
library(knitr)
library(tseries)
```
### Question 1
(a)
```{r, echo=TRUE}
dat <- read.csv("LakeLevels.csv", header = TRUE)
head(dat, 10)
tail(dat, 10)
names(dat)
plot(dat$LakeLevel, ylab="Lake level (m)", main="Daily lake levels")
```
This scatter plot is not exactly how we want to represent our time series data
because the x-axis is not very meaningful as simply an observation index. It
would be more helpful if the x-axis described a time scale. Also, we would like
to join our observations with a line to approximate a continuous time process
(b)
```{r, echo=TRUE}
# check if dat is a ts object
is.ts(dat)
# create time series object
x <- ts(data = dat$LakeLevel, start=c(2007, 1), frequency=365)
```
(c)
```{r, echo=TRUE}
# plot
plot(x, xlab="Year", ylab="Lake level", main="Daily lake levels")
# plot
plot(y, xlab="Year", ylab="Lake level (m)", main="Daily lake levels")
set.seed(2022)
white_noise <- rnorm(200)
# create ts
y <- ts(rnorm(200))
```
(b)
```{r, echo=TRUE}
# plot
plot(y, xlab="Year", ylab="Lake level (m)", main="Daily lake levels")
# plot
plot(y, xlab="Time")
# plot
plot(y)
set.seed(2022)
white_noise <- rnorm(200)
# create ts
y <- ts(rnorm(200))
```
(b)
```{r, echo=TRUE}
# plot
plot(y)
plot(y)
set.seed(2022)
white_noise <- rnorm(200)
# create ts
y <- ts(rnorm(200))
```
(b)
```{r, echo=TRUE}
# plot
plot(y)
set.seed(2022)
white_noise <- rnorm(200)
# create ts
y <- ts(rnorm(200))
```
(b)
```{r, echo=TRUE}
# plot
plot(y)
# This gives the amount of observations that are outside [-2, 2]
sum(abs(y) > 2)
```
For a standard normal distribution, we expect about 5% of the observations to
be outside the range [-2, 2]. Thus with 200 observations we expect 10 to be
outside [-2, 2].
(c)
```{r, echo=TRUE}
# create the sample autocorrelation function
acf(y, lag.max=30, plot = F)
acf(y, lag.max=30)
?sum
?abs
y = c(1, -2, 3)
abs(y)
y
a = abs(y)
y>2
boo <- c(TRUE, FALSE, TRUE)
sum(boo)
boo <- c(TRUE, FALSE, TRUE)
sum(boo)
